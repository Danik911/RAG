{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 cohere==5.5.0 openai==1.30.1 llama-index-embeddings-openai==0.1.9 llama-index-llms-cohere==0.2.0 qdrant-client==1.9.1 llama-index-vector-stores-qdrant==0.2.8"
   ],
   "id": "3aec5d4ecdd37aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "222cc5cfec60e1cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:47:24.641622Z",
     "start_time": "2025-03-03T20:47:24.636892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "CO_API_KEY = os.environ.get('CO_API_KEY') or getpass(\"Enter CO_API_KEY: \")\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or getpass(\"Enter OPENAI_API_KEY: \")\n",
    "QDRANT_URL = os.environ.get('QDRANT_URL') or getpass(\"Enter QDRANT_URL: \")\n",
    "QDRANT_API_KEY = os.environ.get('QDRANT_API_KEY') or getpass(\"Enter QDRANT_API_KEY: \")\n"
   ],
   "id": "5da5ad8759268075",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install requests",
   "id": "a47b89e2480679fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "def create_directory(directory_name):\n",
    "    path = Path(directory_name)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Directory '{directory_name}' created successfully.\")\n",
    "\n",
    "create_directory(\"rag_articles\")"
   ],
   "id": "78f49fbe1dbbdc71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def download_pdf(url, directory):\n",
    "    # Extract a simple filename from the URL (e.g., \"2502.20364.pdf\")\n",
    "    filename = url.split(\"/\")[-1] + \".pdf\"\n",
    "    pdf_path = Path(directory) / filename\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Optional: raises an exception for bad responses\n",
    "    with open(pdf_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"PDF downloaded and saved to {pdf_path}\")\n",
    "    return str(pdf_path)"
   ],
   "id": "6f85f387705219eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of PDF links\n",
    "pdf_links = [\n",
    "    \"https://arxiv.org/pdf/2502.20964\",\n",
    "    \"https://arxiv.org/pdf/2502.20969\",\n",
    "    \"https://arxiv.org/pdf/2502.20995\",\n",
    "    \"https://arxiv.org/pdf/2502.21087\",\n",
    "    \"https://arxiv.org/pdf/2502.21263\"\n",
    "]"
   ],
   "id": "6e7bf6cac0cd5261",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "downloaded_files = []\n",
    "for url in pdf_links:\n",
    "    file_path = download_pdf(url, \"rag_articles\")\n",
    "    downloaded_files.append(file_path)"
   ],
   "id": "289cc289924e0e3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the downloaded PDFs using SimpleDirectoryReader from llamaindex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Option 1: Load using a list of file paths\n",
    "documents = SimpleDirectoryReader(input_files=downloaded_files, filename_as_id=True).load_data()\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ],
   "id": "5b324cfa5f564656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Node parser\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=16,\n",
    "    paragraph_separator=\"\\n\\n\\n\\n\"\n",
    ")"
   ],
   "id": "c1fef7d33671c750",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Instantiate embedding model\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")"
   ],
   "id": "6b4bdea6f58fed55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import qdrant_client\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "# initialize qdrant client\n",
    "client = qdrant_client.QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"rag_articles\",\n",
    "    embed_model=embed_model,\n",
    ")"
   ],
   "id": "18691cd3631b470a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "# assign qdrant vector store to storage context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    )"
   ],
   "id": "51fcfc1d47673828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.core import  VectorStoreIndex\n",
    "\n",
    "# create the index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    show_progress=True,\n",
    "    store_nodes_override=True,\n",
    "    transformation=[sentence_splitter],\n",
    "    embed_model=embed_model,\n",
    "    storage_context=storage_context,\n",
    ")"
   ],
   "id": "7c1cb6baeb984920",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "retirever = index.as_retriever(\n",
    "    similarity_top_k=5,\n",
    "    similarity_threshold=0.75)"
   ],
   "id": "7f4b8a7881dd72b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import qdrant_client\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "\n",
    "# initialize qdrant client\n",
    "client = qdrant_client.QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"rag_articles\",\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "# assign qdrant vector store to storage context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    )\n",
    "\n",
    "# load your index from stored vectors\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    "    storage_context=storage_context\n",
    ")"
   ],
   "id": "7bf8844e8712369d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "\n",
    "llm = Cohere(model=\"command-r-plus\")\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm, streaming=True)\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"How I can build an AI agent?\"\n",
    ")\n",
    "\n",
    "response.print_response_stream()"
   ],
   "id": "4f1bbed16e8c98d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response.source_nodes[0].get_text()",
   "id": "651d0ab329ebaa95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:43:47.792543Z",
     "start_time": "2025-03-03T20:38:31.291321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_engine = index.as_chat_engine(llm=llm)\n",
    "\n",
    "chat_engine.streaming_chat_repl()"
   ],
   "id": "5aae56cd4545c7f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant:  AI agents can be used in a variety of specialized domains, including legal systems, research, recommender systems, cybersecurity, and global security. These domains benefit from the advanced capabilities that AI agents offer, such as natural language processing, machine learning, and automation. AI agents can process and analyze large amounts of data, identify patterns, make recommendations, and support decision-making processes in these domains.\n",
      "\n",
      "Assistant:  AI can significantly enhance the legal system by facilitating complex connection identification and analysis within case law, statutes, and legal precedents. This capability can be leveraged to predict legal trends and uncover hidden relationships, ultimately contributing to improved efficiency and the delivery of justice. Additionally, AI proves valuable in legal research, streamlining the process of collecting, understanding, and retrieving relevant legal documents and statutes.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m chat_engine \u001B[38;5;241m=\u001B[39m index\u001B[38;5;241m.\u001B[39mas_chat_engine(llm\u001B[38;5;241m=\u001B[39mllm)\n\u001B[1;32m----> 3\u001B[0m chat_engine\u001B[38;5;241m.\u001B[39mstreaming_chat_repl()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\chat_engine\\types.py:354\u001B[0m, in \u001B[0;36mBaseChatEngine.streaming_chat_repl\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    352\u001B[0m response\u001B[38;5;241m.\u001B[39mprint_response_stream()\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 354\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHuman: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1260\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_request(\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;28mstr\u001B[39m(prompt),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_ident[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_parent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1266\u001B[0m     password\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1267\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9133cacca60d10ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
